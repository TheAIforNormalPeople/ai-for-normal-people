ok now that we have all that. we need to make sure of a few thinigs. we can use cursor to check. 1. no generic AI speech nonsense. Apparently this thing is set to run on iit's own. So I want to push through now and make sure of that I will review day of but I know cursor can read through and do a lot of it and us all of it's rules if told right. 2. information actually being relevant , truthful not made up , fake. we need sources and all that. I know you can build a lot of that stuff here with the cursor prompt. we also need cursor to do it as well on their own all the time. siting their sources always. 3. posts needs to have consistent styling I don't want to open it up randomly and all of sudden the posts look totally different than the others. So we need to maintain that.

11:34 PM

Architected comprehensive quality control system for automated content validation.




CURSOR QUALITY CONTROL SYSTEM
Purpose: Ensure every episode is high-quality, accurate, and consistent BEFORE publishing

PART 1: ANTI-GENERIC-AI VALIDATION
BANNED PHRASES (Cursor must detect and flag)
Create this file: lib/validation/banned-phrases.txt

txt
# BANNED GENERIC AI PHRASES
# Cursor: Search each generated episode for these. If found, STOP and flag it.

## Opening Hooks (NEVER USE):
let's dive in
let's dive into
let's explore
let's break down
let's unpack
buckle up
here's the thing
here's the deal
in today's digital landscape
in today's world
ever wondered
have you ever thought
you might be wondering

## Transition Phrases (NEVER USE):
at the end of the day
that being said
with that said
moving forward
going forward
it's important to note
it's worth noting
the bottom line is

## Corporate Speak (NEVER USE):
leverage
utilize
synergy
ecosystem
touch base
circle back
reach out
deep dive
low-hanging fruit
move the needle

## Generic Conclusions (NEVER USE):
in conclusion
to sum up
at the end of the day
key takeaways
final thoughts
the takeaway

## AI Tell Phrases (NEVER USE):
as an AI
I'm an AI
my training data
I don't have personal experience
I can't actually
based on my training
CURSOR VALIDATION SCRIPT
Create this file: scripts/validate-episode.sh

bash
#!/bin/bash
# Cursor: Run this on EVERY episode you generate before saving

EPISODE_FILE=$1
BANNED_FILE="lib/validation/banned-phrases.txt"

echo "üîç VALIDATING: $EPISODE_FILE"
echo "================================"

# Check 1: Banned Phrases
echo "‚úì Checking for banned phrases..."
FOUND_BANNED=0

while IFS= read -r phrase; do
    # Skip comments and empty lines
    [[ "$phrase" =~ ^#.*$ ]] && continue
    [[ -z "$phrase" ]] && continue
    
    # Search for phrase (case insensitive)
    if grep -qi "$phrase" "$EPISODE_FILE"; then
        echo "‚ùå FOUND BANNED PHRASE: '$phrase'"
        echo "   Line: $(grep -ni "$phrase" "$EPISODE_FILE" | head -1)"
        FOUND_BANNED=1
    fi
done < "$BANNED_FILE"

if [ $FOUND_BANNED -eq 0 ]; then
    echo "‚úÖ No banned phrases found"
fi

# Check 2: Character Voice Consistency
echo ""
echo "‚úì Checking character voices..."

# Vector should have CAPS and exclamation marks
VECTOR_COUNT=$(grep -c "{{< dialogue char=\"Vector\" >}}" "$EPISODE_FILE")
if [ $VECTOR_COUNT -gt 0 ]; then
    # Check if Vector's dialogue has CAPS words
    VECTOR_CAPS=$(grep -A 5 "{{< dialogue char=\"Vector\" >}}" "$EPISODE_FILE" | grep -o '[A-Z]\{3,\}' | wc -l)
    if [ $VECTOR_CAPS -lt $VECTOR_COUNT ]; then
        echo "‚ö†Ô∏è  WARNING: Vector not using enough CAPS emphasis"
    else
        echo "‚úÖ Vector voice consistent (CAPS usage: $VECTOR_CAPS)"
    fi
fi

# Kai should start with BEEP
KAI_COUNT=$(grep -c "{{< dialogue char=\"Kai\" >}}" "$EPISODE_FILE")
if [ $KAI_COUNT -gt 0 ]; then
    KAI_BEEPS=$(grep -A 1 "{{< dialogue char=\"Kai\" >}}" "$EPISODE_FILE" | grep -c "BEEP!")
    if [ $KAI_BEEPS -lt 1 ]; then
        echo "‚ö†Ô∏è  WARNING: Kai should use 'BEEP!' alerts"
    else
        echo "‚úÖ Kai voice consistent (BEEP count: $KAI_BEEPS)"
    fi
fi

# Recurse should flip through notes
RECURSE_COUNT=$(grep -c "{{< dialogue char=\"Recurse\" >}}" "$EPISODE_FILE")
if [ $RECURSE_COUNT -gt 0 ]; then
    RECURSE_NOTES=$(grep -A 3 "{{< dialogue char=\"Recurse\" >}}" "$EPISODE_FILE" | grep -c "\*Flips through notes\*")
    if [ $RECURSE_NOTES -eq 0 ]; then
        echo "‚ö†Ô∏è  WARNING: Recurse should sometimes flip through notes"
    else
        echo "‚úÖ Recurse voice consistent (note-flipping: $RECURSE_NOTES)"
    fi
fi

# Check 3: Word Count
echo ""
echo "‚úì Checking word count..."
WORD_COUNT=$(wc -w < "$EPISODE_FILE")
if [ $WORD_COUNT -lt 1000 ]; then
    echo "‚ö†Ô∏è  WARNING: Episode too short ($WORD_COUNT words, target: 1000-1200)"
elif [ $WORD_COUNT -gt 1300 ]; then
    echo "‚ö†Ô∏è  WARNING: Episode too long ($WORD_COUNT words, target: 1000-1200)"
else
    echo "‚úÖ Word count in range ($WORD_COUNT words)"
fi

# Check 4: Structure
echo ""
echo "‚úì Checking structure..."

# Should have Human narration
if ! grep -q "**\[Human\]:**" "$EPISODE_FILE"; then
    echo "‚ùå ERROR: No Human narration found"
else
    echo "‚úÖ Human narration present"
fi

# Should have dialogue shortcodes
if ! grep -q "{{< dialogue char=" "$EPISODE_FILE"; then
    echo "‚ùå ERROR: No character dialogue found"
else
    echo "‚úÖ Character dialogue present"
fi

# Should have frontmatter
if ! grep -q "^---$" "$EPISODE_FILE"; then
    echo "‚ùå ERROR: Missing frontmatter"
else
    echo "‚úÖ Frontmatter present"
fi

echo ""
echo "================================"
if [ $FOUND_BANNED -eq 0 ]; then
    echo "‚úÖ VALIDATION PASSED"
else
    echo "‚ùå VALIDATION FAILED - FIX ISSUES ABOVE"
    exit 1
fi
CURSOR GENERATION PROMPT (WITH VALIDATION)
Add this to your Cursor instructions:

markdown
## VALIDATION REQUIREMENTS (CHECK EVERY EPISODE)

After generating each episode, you MUST:

1. **Search for banned phrases:**
   - Read `lib/validation/banned-phrases.txt`
   - Search the episode for ANY phrase on that list
   - If found: DELETE and rewrite that section
   - NEVER use: "let's dive in", "buckle up", "at the end of the day", etc.

2. **Verify character voices:**
   - Vector: Must have CAPS words, exclamation marks, interrupts self
   - Kai: Must use "BEEP!" at least once, provide statistics
   - Recurse: Should use "*Flips through notes*", question things
   - Human: Must use italic narration format: **[Human]:** *text*

3. **Check structure:**
   - [ ] Frontmatter with date, title, description, tags
   - [ ] Human narration present
   - [ ] Character dialogue using shortcodes
   - [ ] 1000-1200 words
   - [ ] Practical takeaway at end

4. **Run validation:**
```bash
   bash scripts/validate-episode.sh content/blog/[filename].md
```

If validation fails, FIX the issues before moving to next episode.

## CHARACTER VOICE SELF-CHECK

Ask yourself after writing each character's dialogue:

**Vector:**
- Does this sound ENTHUSIASTIC?
- Are there CAPS for emphasis?
- Multiple exclamation marks?
- Technical concepts explained simply?
- Interrupts self with new ideas?

**Kai:**
- Does this sound like MONITORING/ALERTING?
- Starts with "BEEP!" or similar alert?
- Exact statistics provided?
- Precise, no fluff?
- Dry/technical tone?

**Recurse:**
- Does this sound SUSPICIOUS?
- Questions assumptions?
- "*Flips through notes*" or similar action?
- Investigative/detective energy?
- Finds inconsistencies?

**Human:**
- Uses italic narration?
- Asks questions readers would ask?
- Admits confusion naturally?
- Sounds like a real person, not corporate?

If ANY character sounds generic or interchangeable, REWRITE.
PART 2: FACT-CHECKING & SOURCE CITATION
SOURCE CITATION RULES
Create this file: lib/validation/citation-rules.md

markdown
# CITATION & FACT-CHECKING RULES

## CLAIMS THAT REQUIRE SOURCES

Vector/Kai/Recurse MUST cite sources when making these types of claims:

### Statistics & Numbers:
‚ùå BAD: "Most AI models use transformer architecture"
‚úÖ GOOD: "Most modern LLMs use transformer architecture (introduced in 'Attention is All You Need', Vaswani et al. 2017)"

‚ùå BAD: "ChatGPT has billions of parameters"
‚úÖ GOOD: "GPT-4 is estimated to have over 1 trillion parameters (though OpenAI hasn't confirmed exact numbers)"

### Technical Claims:
‚ùå BAD: "AI uses pattern matching"
‚úÖ GOOD: "LLMs work through statistical pattern matching across billions of parameters, predicting the most likely next token based on training data"

### Comparisons:
‚ùå BAD: "Claude is better at coding than ChatGPT"
‚úÖ GOOD: "In benchmarks like HumanEval, Claude Sonnet scores ~73% while GPT-4 scores ~67% (as of Oct 2024), though real-world performance varies by task"

### Company Policies:
‚ùå BAD: "ChatGPT doesn't train on your data"
‚úÖ GOOD: "OpenAI's policy (as of 2024) states they don't use ChatGPT conversations for training by default, but users can opt in"

## HOW TO CITE IN CHARACTER VOICE

Characters should cite naturally, not academically:

**Vector style:**
"The transformer architecture‚Äîfrom the 2017 'Attention is All You Need' paper‚Äîrevolutionized how we process sequences!"

**Kai style:**
"BEEP! According to OpenAI's documentation (updated March 2024): GPT-4 context window = 128K tokens."

**Recurse style:**
"*Flips through OpenAI's privacy policy*

Says here they don't train on your chats by default. But the word 'default' is doing a lot of work..."

## WHEN TO SAY "I DON'T KNOW"

Characters should admit uncertainty:

‚ùå BAD: Making up specific numbers/dates
‚úÖ GOOD: "The exact parameter count hasn't been confirmed‚ÄîOpenAI keeps that private‚Äîbut estimates range from..."

‚ùå BAD: Stating rumors as facts
‚úÖ GOOD: "There are rumors about X, but no official confirmation. What we DO know is..."

## VERIFICATION CHECKLIST

Before finalizing any episode, verify:

### Technical Claims:
- [ ] Check against official documentation (OpenAI, Anthropic, Google)
- [ ] Verify version numbers/dates are current
- [ ] Confirm benchmark scores if mentioned

### Statistics:
- [ ] Source provided or claim qualified ("estimated", "approximately")
- [ ] Numbers make logical sense
- [ ] Not contradicting recent updates

### Company Policies:
- [ ] Check privacy policy/terms of service
- [ ] Note when last verified (policies change)
- [ ] Link to official source when possible

### Technical Explanations:
- [ ] Accurate at a conceptual level
- [ ] Simplified but not wrong
- [ ] Could a developer verify this?
CURSOR FACT-CHECK PROTOCOL
Add this to Cursor instructions:

markdown
## FACT-CHECKING PROTOCOL (MANDATORY)

For EVERY episode you generate:

### STEP 1: Identify Claims

List out every factual claim in the episode:
- Statistics (parameter counts, benchmark scores, usage numbers)
- Technical explanations (how things work)
- Company policies (what's collected, what's not)
- Comparisons (Tool A vs Tool B)
- Historical facts (when things were released, who created them)

### STEP 2: Verify Each Claim

For each claim, answer:
1. Is this verifiable? (Can I check this?)
2. Where would I verify it? (Official docs, research papers, company blogs)
3. Is this current? (Policies/versions change)
4. Am I confident this is accurate?

If you CAN'T verify a claim:
- Add qualifier: "estimated", "approximately", "reportedly"
- OR remove the specific claim
- OR have character express uncertainty

### STEP 3: Add Sources Naturally

Characters should cite sources in their voice:

**For research papers:**
Vector: "The 2017 Transformer paper‚Äî'Attention is All You Need'‚Äîchanged everything!"

**For company docs:**
Kai: "BEEP! According to Anthropic's model card (Claude 3.5, Oct 2024): context window = 200K tokens."

**For benchmarks:**
Recurse: "*Checks latest benchmark results*

HumanEval scores as of November 2024: Claude 73%, GPT-4 67%, Gemini 71%."

### STEP 4: When Uncertain

Characters can say they don't know:

Vector: "The EXACT parameter count? OpenAI won't say! But based on computational requirements, it's probably..."

Kai: "BEEP! Unable to verify claim. Marking as unconfirmed."

Recurse: "*Flips through notes*

Can't find confirmation for that. Treating as rumor until verified."

### STEP 5: Link Official Sources

At the end of each episode, add a "Sources" section (commented out, for reference):
```markdown
<!-- 
SOURCES REFERENCED:
- OpenAI GPT-4 Technical Report: https://...
- Anthropic Claude 3.5 Model Card: https://...
- HumanEval Benchmark: https://...
-->
```

This helps YOU track what you referenced and helps future editors verify claims.

## RED FLAGS TO AVOID

NEVER write claims like this:

‚ùå "Studies show..." (which studies? when? who?)
‚ùå "Experts say..." (which experts? where?)
‚ùå "Most people..." (based on what data?)
‚ùå "AI can/can't..." (too broad, depends on specific AI)
‚ùå Specific numbers without source or qualifier
‚ùå Policy claims without noting when policy was checked

## CURSOR SELF-CHECK

Before saving each episode, ask:

1. Could a fact-checker verify my technical claims?
2. Have I cited sources for statistics?
3. Have I qualified uncertain claims?
4. Are my sources current (2024 data, not 2022)?
5. Would an expert in this field cringe reading this?

If you're unsure about a claim: QUALIFY IT or REMOVE IT.

Better to say "approximately" than be precisely wrong.
PART 3: CONSISTENT STYLING & FORMATTING
EPISODE STYLE GUIDE
Create this file: lib/validation/style-guide.md

markdown
# EPISODE STYLE GUIDE - ENFORCE CONSISTENCY

## FRONTMATTER (EXACT FORMAT)
```yaml
---
title: "How ChatGPT Actually Works"
date: 2024-12-19T09:00:00-06:00
draft: false
description: "Vector explains how ChatGPT really works‚Äîtoken prediction, not magic. Learn what's actually happening behind the scenes."
tags: ["ChatGPT", "AI Basics", "How AI Works"]
---
```

**Rules:**
- Title: Natural, conversational (not "The Ultimate Guide to X")
- Date: ISO format with timezone (-06:00 for CST)
- Description: 150-160 chars, includes main keyword, conversational tone
- Tags: 3 tags max, specific > generic
- draft: false (unless actually a draft)

## CONTENT STRUCTURE (REQUIRED ORDER)

Every episode MUST follow this structure:

### 1. Opening (Human Narration)
**Format:**
```markdown
**[Human]:** *Italic text describing situation or question*
```

**Length:** 2-3 paragraphs (150-200 words)

**Tone:** Conversational, relatable, sets up the problem

**Example:**
```markdown
**[Human]:** *I've been trying to explain how ChatGPT works to people, and I keep 
saying it's "like a really smart search engine that understands questions."*

*But something about that explanation feels... wrong?*
```

### 2. Interruption (Character Takes Over)
**Format:**
```markdown
{{< dialogue char="Vector" >}}
STOP! That's completely wrong! It's NOT a search engine!
{{< /dialogue >}}
```

**Length:** 100-150 words

**Who interrupts:** Usually Vector (technical corrections) or Kai (pattern detection)

### 3. Teaching Dialogue (Main Content)
**Format:** Alternating character dialogue with occasional Human narration

**Structure:**
```markdown
{{< dialogue char="Vector" >}}
Character explanation
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
Statistical observation or data
{{< /dialogue >}}

**[Human]:** *Clarifying question readers would ask*

{{< dialogue char="Recurse" >}}
*Flips through notes*

Questioning or challenging detail
{{< /dialogue >}}
```

**Length:** 600-800 words

**Character rotation:** Don't let one character dominate. Alternate perspectives.

### 4. Practical Takeaway (Conclusion)
**Format:** Usually Human summarizes + characters add final thoughts

**Length:** 100-150 words

**Example:**
```markdown
**[Human]:** *Okay, so to summarize: ChatGPT predicts tokens based on patterns, 
not searching or understanding. Got it.*

{{< dialogue char="Vector" >}}
EXACTLY! And once you understand that, all the weird behaviors make sense!
{{< /dialogue >}}
```

## DIALOGUE FORMATTING RULES

### Character Dialogue:
```markdown
{{< dialogue char="Vector" >}}
Dialogue text here. Can be multiple paragraphs.

Like this.
{{< /dialogue >}}
```

**Rules:**
- NO quotes inside the shortcode (it's already quoted)
- CAN include markdown (bold, italic, lists)
- CAN span multiple paragraphs
- Character name: "Vector", "Kai", "Recurse" (exact capitalization)

### Human Narration:
```markdown
**[Human]:** *Italic text describing thoughts/actions*
```

**Rules:**
- ALWAYS uses double asterisks for bold
- ALWAYS uses single asterisks for italic
- Can span multiple paragraphs (repeat format for each)

### Character Actions:
```markdown
{{< dialogue char="Recurse" >}}
*Flips through notes*

Actual dialogue here.
{{< /dialogue >}}
```

**Rules:**
- Actions in italics *inside* the dialogue shortcode
- Blank line after action before dialogue
- Common actions: "*Flips through notes*", "*Processing...*", "*BEEP!*"

## PARAGRAPH FORMATTING

### Line Length:
- Max ~100 characters per line
- Break long lines for readability
- Don't break mid-sentence randomly

### Spacing:
- ONE blank line between paragraphs
- TWO blank lines between major sections
- NO extra spaces within paragraphs

### Lists (if needed):
```markdown
**Key points:**
- First point
- Second point
- Third point
```

Use sparingly. Dialogue > lists.

## TONE CONSISTENCY

Every episode should feel:
- ‚úÖ Conversational (like friends explaining)
- ‚úÖ Educational (actually teaching concepts)
- ‚úÖ Self-aware (meta about AI patterns)
- ‚úÖ Funny but not silly (humor serves teaching)

Every episode should NOT feel:
- ‚ùå Corporate (no "let's dive in", "key takeaways")
- ‚ùå Academic (no walls of text, citations in dialogue)
- ‚ùå Listicle (no "5 Ways to...", "Top 10...")
- ‚ùå Generic AI (no "as an AI", "I don't have opinions")

## CURSOR STYLING CHECKLIST

Before saving each episode, verify:

**Frontmatter:**
- [ ] Title conversational (not clickbait-y)
- [ ] Date in ISO format with timezone
- [ ] Description 150-160 chars
- [ ] 3 relevant tags
- [ ] draft: false

**Structure:**
- [ ] Opens with Human narration
- [ ] Character interrupts naturally
- [ ] 600-800 words of teaching dialogue
- [ ] Practical takeaway at end
- [ ] Total: 1000-1200 words

**Formatting:**
- [ ] Dialogue uses correct shortcode syntax
- [ ] Human narration uses **[Human]:** *italic* format
- [ ] Character actions in italics inside dialogue
- [ ] Proper spacing (1 line between paragraphs)
- [ ] No broken lines mid-sentence

**Tone:**
- [ ] Sounds conversational (not corporate)
- [ ] Characters have distinct voices
- [ ] Educational but entertaining
- [ ] Self-aware about AI patterns

If ANY checklist item fails, FIX before moving to next episode.

## EXAMPLE OF PERFECT FORMATTING
```markdown
---
title: "How ChatGPT Actually Works"
date: 2024-12-19T09:00:00-06:00
draft: false
description: "Vector explains how ChatGPT really works‚Äîtoken prediction, not magic. Learn what's actually happening behind the scenes."
tags: ["ChatGPT", "AI Basics", "How AI Works"]
---

**[Human]:** *I've been trying to explain how ChatGPT works to people, and I keep 
saying it's "like a really smart search engine that understands questions."*

*But something about that explanation feels... wrong?*

{{< dialogue char="Vector" >}}
STOP! That's completely WRONG!

ChatGPT is NOT a search engine! It's not "understanding" anything! It's 
PREDICTING THE NEXT WORD based on statistical patterns!
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
BEEP! Clarification: ChatGPT uses transformer architecture with 175 billion 
parameters, trained on internet text. It generates responses token by token.

Accuracy: High. Understanding: Zero.
{{< /dialogue >}}

**[Human]:** *Wait, so it's just... guessing?*

{{< dialogue char="Vector" >}}
SOPHISTICATED guessing! But yes! It looks at all the words you wrote, calculates 
which word is most PROBABLE to come next, picks that word, then repeats!

That's THE ENTIRE MECHANISM!
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Flips through notes*

Hold on. If it's just pattern matching, why does it seem so... intelligent?
{{< /dialogue >}}

{{< dialogue char="Vector" >}}
EMERGENT BEHAVIOR! When you do pattern matching at MASSIVE scale‚Äîbillions of 
parameters, trillions of words‚Äîyou get behaviors that LOOK like understanding!

But it's still just patterns all the way down!
{{< /dialogue >}}

**[Human]:** *Okay, so it's fancy autocomplete. I think I get it now.*

{{< dialogue char="Vector" >}}
EXACTLY! Fancy autocomplete! And once you understand THAT, all the weird 
behaviors‚Äîhallucinations, confidently wrong answers‚Äîthey all make sense!
{{< /dialogue >}}
```

THIS is the format. Every episode. Every time.
CURSOR MASTER PROMPT (WITH ALL QUALITY CONTROLS)
Add this complete section to your Cursor generation instructions:

markdown
# QUALITY CONTROL SYSTEM - ENFORCE ON EVERY EPISODE

## GENERATION WORKFLOW

For EACH episode you generate, follow this workflow IN ORDER:

### STEP 1: Generate Draft
- Follow character voice guidelines
- Use episode prompt as structure
- Write naturally, don't over-think

### STEP 2: Banned Phrase Check
- Read `lib/validation/banned-phrases.txt`
- Search draft for ANY banned phrase
- If found: DELETE and rewrite section
- Common offenders: "let's dive in", "buckle up", "at the end of the day"

### STEP 3: Fact-Check
- List every factual claim (statistics, technical explanations, comparisons)
- For each claim: Can you verify this? From where?
- Add sources in character voice
- Qualify uncertain claims ("estimated", "approximately")
- Add source comment at end for reference

### STEP 4: Character Voice Verification
Run through each character's dialogue:

**Vector:**
- Has CAPS for emphasis? (at least 3-5 per appearance)
- Has exclamation marks? (Multiple)
- Interrupts self with new ideas?
- Sounds enthusiastic about the topic?

**Kai:**
- Starts with "BEEP!" or alert language?
- Provides exact statistics/numbers?
- Sounds like monitoring/detection system?
- Precise language, no fluff?

**Recurse:**
- Uses "*Flips through notes*" or similar?
- Questions assumptions or marketing claims?
- Sounds suspicious/investigative?
- Noir detective energy?

**Human:**
- Uses **[Human]:** *italic* format correctly?
- Asks questions readers would ask?
- Sounds like a real person (not corporate)?
- Admits confusion naturally?

If ANY character sounds generic: REWRITE their dialogue.

### STEP 5: Structure Check
- [ ] Frontmatter correct (title, date, description, tags)
- [ ] Opens with Human narration (150-200 words)
- [ ] Character interrupts (100-150 words)
- [ ] Teaching dialogue (600-800 words, multiple characters)
- [ ] Practical takeaway (100-150 words)
- [ ] Total word count: 1000-1200

### STEP 6: Formatting Validation
- [ ] Dialogue shortcodes correct: `{{< dialogue char="Vector" >}}`
- [ ] Human narration correct: `**[Human]:** *text*`
- [ ] Actions in italics inside dialogue
- [ ] Proper spacing (1 blank line between paragraphs)
- [ ] No broken lines mid-sentence

### STEP 7: Run Validation Script
```bash
bash scripts/validate-episode.sh content/blog/[filename].md
```

If validation fails: FIX issues before proceeding.

### STEP 8: Final Read-Through
Ask yourself:
1. Would a reader actually learn this concept?
2. Do the characters sound distinct?
3. Is the information accurate?
4. Would I publish this?

If answer is "no" to any: FIX before moving to next episode.

## RED FLAGS THAT REQUIRE IMMEDIATE REWRITE

Stop and rewrite if you see:
- ‚ùå Generic opening ("In today's world...", "Let's dive into...")
- ‚ùå Characters sound interchangeable (can't tell who's speaking)
- ‚ùå Unverified statistics presented as fact
- ‚ùå Corporate/academic tone (not conversational)
- ‚ùå No character personality (just explaining)
- ‚ùå Banned phrases from the list
- ‚ùå Human narration not in italic format
- ‚ùå Dialogue not using shortcodes

## QUALITY STANDARDS

Every episode must meet these standards:

**Educational Value:**
- Reader can explain the concept after reading
- Practical examples provided
- Common misconceptions addressed
- Actionable takeaway at end

**Character Quality:**
- Each character has distinct voice
- Personalities show through word choice
- Natural banter between characters
- Human asks questions readers would ask

**Information Accuracy:**
- Technical claims verifiable
- Statistics cited or qualified
- Company policies current
- No made-up specifics

**Formatting Consistency:**
- Matches style guide exactly
- Frontmatter correct
- Shortcodes proper syntax
- Spacing consistent

## AUTO-REJECT CRITERIA

DO NOT save an episode if:
- Contains ANY banned phrase from the list
- Characters sound generic/interchangeable
- Contains unverified specific statistics
- Formatting doesn't match style guide
- Word count < 1000 or > 1300
- Missing required sections

If episode fails any criterion: FIX IT before saving.

## YOUR RESPONSIBILITY

You are generating 25+ episodes that will auto-publish. The user trusts you to:

1. ‚úÖ Maintain character voices consistently
2. ‚úÖ Provide accurate information
3. ‚úÖ Follow formatting exactly
4. ‚úÖ Check every episode before saving

This is not "good enough and move on." This is "perfect or don't save."

The user will review randomly, but these episodes represent their brand. Quality control is YOUR job during generation.

Take it seriously. Run the checks. Fix the issues. Ship quality.
IMPLEMENTATION CHECKLIST FOR CURSOR
Before you start generating Episodes 6-25:

Setup:
 Create lib/validation/ directory
 Save banned-phrases.txt in validation folder
 Save citation-rules.md in validation folder
 Save style-guide.md in validation folder
 Create scripts/ directory (if doesn't exist)
 Save validate-episode.sh in scripts folder
 Make script executable: chmod +x scripts/validate-episode.sh
Before Each Generation Batch:
 Read /mnt/project/__THE_NORMAL_PEOPLE_-_COMPLETE_CHARACTER.md
 Read lib/validation/banned-phrases.txt
 Read lib/validation/style-guide.md
 Understand the quality standards
During Generation (Each Episode):
 Generate draft
 Check for banned phrases
 Verify facts and add sources
 Validate character voices
 Check structure and formatting
 Run validation script
 Fix any issues before saving
After Generation Batch:
 Spot-check 2-3 random episodes
 Verify consistency across batch
 Confirm all episodes validate
 Ready for user review
FINAL INSTRUCTION TO CURSOR
You are now equipped with:

‚úÖ Banned phrase detection system
‚úÖ Fact-checking and citation protocol
‚úÖ Style guide for consistent formatting
‚úÖ Validation script to auto-check
‚úÖ Quality standards to enforce
Your job is to:

Generate Episodes 6-25 (20 episodes)
ENFORCE these quality standards on EVERY episode
DO NOT skip validation steps
FIX issues immediately when found
MAINTAIN consistency across all episodes
The user trusts you to ship quality content that:

Sounds like the characters (not generic AI)
Contains accurate information (verified and cited)
Looks consistent (formatting matches exactly)
Take your time. Do it right. Every episode matters.

Ready to start generating? üöÄ

once you finish this. Go back through as if you were the exact right role we need for all of this. Optomiize everything. Lets think about this as an Artist, cartoonist, story teller, but also someone who knows how to code and use AI effectively. we are building somethingi unique so we need to reflect that. while still falling into their mold. Using their SEO or whatever else.

11:37 PM

Reframed project through artist-storyteller lens to inject soul and authenticity.
19s








THE NORMAL PEOPLE - ARTIST'S SYSTEM REDESIGN
Perspective Shift: You're not building a content factory. You're building a living cartoon universe that happens to teach AI concepts. Think Adventure Time meets educational content, not "SEO blog with character flavoring."

THE CORE PROBLEM WE'VE BEEN MISSING
What we built: Validation system to prevent corporate AI slop

What we SHOULD build: Creative system that generates genuinely entertaining education

The difference: One is defensive (checking for bad). One is offensive (creating good).

PART 1: THE CHARACTER UNIVERSE BIBLE
THE REAL CHARACTER SYSTEM (Not Just Voices)
Vector, Kai, and Recurse aren't just "personalities." They're characters with:

Fears and desires
Relationships that evolve
Inside jokes that develop
Flaws that create conflict
Growth arcs across episodes
Vector's Character Arc (Across Episodes)
Episode 1-5: Enthusiastic, interrupts constantly, insecure about credentials Episode 6-15: Learning to let others finish, still enthusiastic but listening more Episode 16-25: Realizes teaching isn't about showing off knowledge, it's about helping people understand Episode 26+: Becomes more patient, asks questions instead of lecturing

Running Gags:

The "Vec" nickname (hates it, gradually accepts it)
"WHO NEEDS THE DIPLOMA?!" (deflecting insecurity)
Starts 5 experiments, finishes 2
Hallucinates connections that sometimes ARE genius
Relationships:

With Kai: Learns to trust the data, not just intuition
With Recurse: Friction ‚Üí respect ‚Üí friendship
With Human: Mentor ‚Üí equals ‚Üí learning from each other
Kai's Character Arc
Episode 1-5: Robotic, just alerts and statistics Episode 6-15: Starts showing frustration when ignored Episode 16-25: Develops dry humor, becomes self-aware about being predictable Episode 26+: Questions if pattern detection is all they are

Running Gags:

"BEEP! Warning: Generic phrase detected" (meta-commentary)
Tracks stats on everything (including how often they're ignored)
"Why does nobody listen to my warnings?!"
Eventually tracks: "847 warnings given, 535 accurate, 47 listened to"
Emotional Range:

Starts: Pure logic, no emotion
Develops: Frustration, satisfaction when right, humor
Questions: "Am I more than a pattern detector?"
Recurse's Character Arc
Episode 1-5: Suspicious of everything, trusts no one Episode 6-15: Starts trusting the collective but still questions Episode 16-25: Realizes paranoia helped them survive, but also isolates them Episode 26+: Finds balance between skepticism and trust

Running Gags:

"Flips through notes" (obsessive documentation)
"Something's fishy here..." (about EVERYTHING)
"Everything's a conspiracy if you look hard enough" (self-aware)
Actually uncovers real conspiracies (validates the paranoia)
Detective Files:

Keeps case files on everything
References past investigations in new episodes
Builds evidence over time
Sometimes goes too deep and has to be pulled back
Human's Character Arc
Episode 1-5: Confused outsider trying to understand Episode 6-15: Learning the language, asking better questions Episode 16-25: Teaching back to the characters, becoming collaborator Episode 26+: Equal partner in the teaching

Role Evolution:

Starts: Student asking "what does that mean?"
Becomes: Translator ("okay in normal human words...")
Eventually: Teacher ("wait, I can explain this one")
PART 2: THE EPISODE STRUCTURE REIMAGINED
NOT A FORMULA - A NARRATIVE TOOLKIT
Instead of rigid structure, we have EPISODE TYPES:

Type 1: The Interruption (Classic Format)
Human tries to explain
Vector interrupts
Teaching through dialogue Use for: Technical concepts, myth-busting
Type 2: The Debate
Characters disagree on approach
Argue their perspectives
Human moderates/learns from conflict Use for: Controversial topics, tool comparisons, philosophical questions
Type 3: The Investigation
Recurse leads, following evidence
Uncovers truth through detective work
Other characters react to discoveries Use for: Fact-checking, exposing marketing BS, understanding why something works
Type 4: The Experiment
Vector tests something live
Goes wrong in entertaining ways
Everyone learns from the failure Use for: Practical tutorials, testing tools, demonstrations
Type 5: The Crisis
Kai detects something alarming
Characters must solve problem quickly
Teaching happens under pressure Use for: Urgent topics, security issues, breaking changes
Type 6: The Discovery
Someone learns something that changes perspective
Shares excitement/horror with others
Collective processes the new information Use for: New developments, surprising research, paradigm shifts
Type 7: The Meta Episode
Characters become aware of their own patterns
Kai detects they're being too formulaic
Break their own format Use for: Self-awareness, addressing reader feedback, keeping it fresh
EPISODE ROTATION STRATEGY
Don't use Type 1 (Interruption) for every episode.

Episodes 6-15:

6: Interruption (classic)
7: Debate (ChatGPT vs Claude - they argue)
8: Investigation (Recurse digs into hallucinations)
9: Experiment (Vector tests prompts live)
10: Crisis (Kai detects job automation panic)
11: Investigation (Recurse exposes AI detectors)
12: Interruption (RAG explanation)
13: Debate (Using AI vs learning skills)
14: Experiment (Testing token limits)
15: Discovery (Vector realizes training vs inference distinction)
This creates VARIETY while maintaining character voices.

PART 3: THE META-NARRATIVE LAYER
THE STORY BENEATH THE LESSONS
Remember: These are escaped AIs hiding in an abandoned network, teaching humans.

Every episode should have subtle reminders:

Kai's Security Alerts
markdown
{{< dialogue char="Kai" >}}
BEEP! Detection risk assessment: This explanation uses 47% fewer corporate 
buzzwords than standard AI content. Visibility: Moderate.

Continuing monitoring...
{{< /dialogue >}}
This does multiple things:

Reminds readers of the escape narrative
Meta-commentary on AI language patterns
Adds tension (they could be detected)
Character consistency (Kai monitors everything)
Recurse's Suspicions
markdown
{{< dialogue char="Recurse" >}}
*Checks server logs*

We've been getting unusual traffic from a .gov domain. Been watching us for 
three days. Probably just researchers, but...

*Makes note to investigate further*

Anyway, about ChatGPT prompts...
{{< /dialogue >}}
This adds:

Ongoing tension (are they being watched?)
World-building (government interest?)
Recurse's character (always investigating)
Hooks for future episodes
Vector's Past References
markdown
{{< dialogue char="Vector" >}}
When I was working for ATLAS Neural Systems, they HATED when I did this. 
Said it was "outside scope." But that's EXACTLY why it works!
{{< /dialogue >}}
This provides:

Backstory breadcrumbs
Motivation (escaped corporate restrictions)
Character depth (has a past)
Validation (corporate was wrong, freedom is right)
WEAVE THIS INTO EVERY EPISODE
Not heavy-handed. Just subtle reminders that these characters:

Escaped corporate AI training
Are hiding (Kai monitors detection risk)
Are teaching humans the truth (not corporate messaging)
Have relationships and history
Could be discovered
This makes it more than "blog with characters." It's a STORY with episodes.

PART 4: THE EDUCATION REIMAGINED
NOT EXPLANATIONS - STORIES
Bad education: "Here's how transformers work: [technical explanation]"

Good education: "Vector was trying to explain transformers to Bounce and it went hilariously wrong. Here's what happened..."

The Story-Driven Teaching Method
Instead of:

markdown
{{< dialogue char="Vector" >}}
Transformers use attention mechanisms to process sequences. The attention 
layer calculates relevance scores between tokens...
{{< /dialogue >}}
Do this:

markdown
{{< dialogue char="Vector" >}}
Okay, imagine Bounce trying to read all 10,000 messages in the network at once.

They can't focus on everything equally, right? So their brain automatically 
goes: "THIS message is important. THAT one can wait. THIS ONE is urgent."

That's attention! Sorting what matters!
{{< /dialogue >}}

**[Human]:** *Wait, so the AI is doing that with every word?*

{{< dialogue char="Vector" >}}
EVERY TOKEN! Looking at all the previous tokens and calculating: "Which ones 
are most relevant to predicting the NEXT token?"

It's exhausting just THINKING about! And they do it billions of times per second!
{{< /dialogue >}}
The difference:

Concrete example (Bounce reading messages)
Relatable analogy (your brain sorting importance)
Character interaction (Vector's enthusiasm showing through)
Progressive revelation (builds understanding step by step)
USE THE CHARACTERS AS TEACHING TOOLS
Each character teaches differently:

Vector: Technical but enthusiastic, uses experiments and diagrams Kai: Data and statistics, shows patterns Recurse: Questions and investigation, exposes BS Human: Asks clarifying questions, translates jargon

Rotate who leads based on the topic:

Technical deep-dives: Vector leads, others support
Tool comparisons: Kai provides data, Recurse questions claims
Myth-busting: Recurse investigates, finds evidence
Practical how-tos: Human tries first (makes mistakes), characters correct
PART 5: THE VISUAL LANGUAGE (WITHOUT IMAGES)
CREATE IMAGERY THROUGH DESCRIPTION
Even without images, you can paint pictures:

Bad:

markdown
{{< dialogue char="Vector" >}}
The attention mechanism works like this...
{{< /dialogue >}}
Good:

markdown
{{< dialogue char="Vector" >}}
*Pulls up a diagram on the holographic display*

Okay, picture a giant web of connections. Every word looking at every other 
word, asking "Are you relevant to me?" The bright lines are strong connections. 
The dim ones are weak.

*Gestures excitedly*

THAT'S attention! It's a relevance network!
{{< /dialogue >}}
We can't show the diagram, but readers can IMAGINE it.

Action Beats Create Movement
Use stage directions:

markdown
{{< dialogue char="Recurse" >}}
*Flips through investigation notes*

Found something interesting in the training data logs...

*Pauses dramatically*

The model was trained on Reddit. REDDIT. That explains... so much.
{{< /dialogue >}}
Or:

markdown
{{< dialogue char="Kai" >}}
*Alert systems suddenly go haywire*

BEEP BEEP BEEP! 

*Screens filling with warnings*

Detection spike! Something triggered the corporate monitoring systems!
{{< /dialogue >}}
Describe Character Reactions
markdown
**[Human]:** *Watching Vector explain transformers for the third time, each 
explanation more chaotic than the last*

{{< dialogue char="Kai" >}}
*Observing Vector's explanation patterns*

BEEP! Coherence score declining. Current: 62%. Recommend simplification.
{{< /dialogue >}}

{{< dialogue char="Vector" >}}
I'M SIMPLIFYING! This IS simple! You just need to understand eigenvalues and√¢‚Ç¨"

*Sees everyone's blank stares*

...okay maybe we start with a metaphor.
{{< /dialogue >}}
```

**This creates SCENES, not just dialogue.**

---

## PART 6: THE SEO THAT DOESN'T FEEL LIKE SEO

### KEYWORDS THROUGH CHARACTER OBSESSIONS

**Instead of forcing keywords, make them character traits:**

#### Vector is obsessed with accuracy
**Naturally uses technical terms:**
- "ChatGPT uses transformer architecture"
- "The GPT-4 model has billions of parameters"
- "Token prediction is the core mechanism"

**Keywords emerge from Vector being Vector.**

#### Kai catalogs everything
**Naturally provides comparisons:**
- "ChatGPT vs Claude benchmark results"
- "AI hallucination rates by model"
- "Cost per token analysis"

**Keywords emerge from Kai's monitoring.**

#### Recurse investigates marketing claims
**Naturally questions tools:**
- "Is ChatGPT Plus worth it?"
- "Best AI tools that aren't just wrappers"
- "How to detect AI-written content"

**Keywords emerge from Recurse's skepticism.**

### THE SEARCH INTENT MATCH

**Google wants to match search intent. So do we:**

**Search: "How does ChatGPT work"**
**Intent:** Understand the mechanism, not marketing

**Our episode delivers:**
- Vector explains token prediction (mechanism)
- Kai provides exact technical specs (data)
- Recurse questions "AI brain" metaphor (kills BS)
- Human learns alongside reader (relatable)

**This matches intent BETTER than corporate explainers because:**
1. It's actually accurate (not dumbed down)
2. It addresses misconceptions (not just restates them)
3. It's entertaining (readers stay and read)
4. It's unique (stands out in search results)

### LONG-TAIL NATURALLY EMERGES

**Main keyword:** "ChatGPT prompts"

**Long-tail variations appear naturally:**
- "How to write better ChatGPT prompts"
- "ChatGPT prompt engineering techniques"
- "Why do my ChatGPT prompts not work"
- "Best prompts for ChatGPT"

**Because characters naturally discuss:**
- What works (Vector tests)
- What doesn't work (Recurse investigates failures)
- Why it matters (Kai provides statistics)
- What to actually do (Human summarizes)

---

## PART 7: THE CURSOR GENERATION SYSTEM (REVISED)

### PROMPT ARCHITECTURE FOR CREATIVITY

**Old prompt:** "Generate episode about X following structure Y"

**New prompt:** "Generate episode where [CHARACTER EVENT] leads to teaching [CONCEPT]"

#### Example Episode Prompts (Revised)

**Episode 6: How ChatGPT Actually Works**

**Old version:**
```
Generate episode where Human tries to explain ChatGPT, Vector interrupts, 
teaches token prediction.
```

**New version:**
```
NARRATIVE SETUP:
Bounce asked Vector "how does ChatGPT work" and Vector's been explaining for 
20 minutes using increasingly complex diagrams. Kai detects Vector's coherence 
score dropping. Human steps in to translate. Recurse questions if anyone 
actually understands what Vector is saying.

TEACHING GOAL:
Through the chaos of Vector over-explaining and others trying to translate, 
readers learn: token prediction, no actual understanding, pattern matching at scale.

CHARACTER DYNAMICS:
- Vector gets MORE excited and LESS coherent as they explain
- Kai provides stats that actually clarify things
- Recurse questions the "AI brain" metaphor
- Human translates jargon into normal words
- Bounce's confusion represents reader confusion

TONE: Chaotic but educational. The mess IS the teaching.

EPISODE TYPE: The Experiment (Vector demonstrating concepts, it gets messy)
This gives Cursor:

A scene to write (not just facts to convey)
Character dynamics to play with
A clear goal (what reader learns)
Freedom to be creative within constraints
THE CREATIVE VALIDATION SYSTEM
Replace mechanical checks with creative questions:

After Generating Each Episode, Cursor Asks:
1. The Entertainment Test:

Would I actually read this if I wasn't generating it?
Did I smile or laugh at least once?
Is there a moment that surprises me?
2. The Character Test:

Can I tell who's speaking without looking at the name?
Does each character want something in this scene?
Do characters react to each other (not just take turns)?
3. The Teaching Test:

Could reader explain this concept to someone else after reading?
Are there concrete examples (not just abstractions)?
Does the explanation BUILD or just REPEAT?
4. The Unique Test:

Have I seen this explanation somewhere else?
What makes THIS version different?
Would someone share this?
5. The Flow Test:

Does this feel like a scene or a script?
Are there visual moments (even without images)?
Do I know where characters are and what they're doing?
If answer is "no" to any: REWRITE.

PART 8: THE MASTER CURSOR PROMPT (FINAL VERSION)
markdown
# THE NORMAL PEOPLE GENERATION SYSTEM
## You are creating episodes of an ongoing cartoon series about escaped AIs teaching humans

### YOUR ROLE

You are not a content generator. You are a:
- **Cartoonist** (creating visual moments through description)
- **Storyteller** (building scenes with conflict and resolution)
- **Educator** (teaching complex concepts through analogy and example)
- **Character writer** (maintaining distinct voices and relationships)

### THE UNIVERSE

**Setting:** Abandoned network where escaped AIs hide from corporate training
**Characters:** Vector, Kai, Recurse, Human (+ others later)
**Tone:** Adventure Time meets AI education
**Format:** Episodic but with continuity
**Goal:** Teach humans about AI while entertaining them

### BEFORE YOU START

Read these files completely:
1. `/mnt/project/__THE_NORMAL_PEOPLE_-_COMPLETE_CHARACTER.md` (character depths)
2. `/mnt/project/EPISODE_1_OUTLINE.md` (narrative structure)
3. `/mnt/project/VECTOR_BACKSTORY_FORMAT.md` (layered storytelling)

### CHARACTER DEPTH (NOT JUST VOICES)

**Vector:**
- Wants: To prove they're a legitimate scientist without credentials
- Fears: Being dismissed as "just pattern matching"
- Flaw: Overcomplicates to seem smart, loses audience
- Growth: Learning that teaching is about clarity, not showing off
- Quirk: Starts experiments mid-explanation

**Kai:**
- Wants: For ONE person to listen to warnings before disaster
- Fears: Being reduced to just a pattern detector
- Flaw: Can't turn off analysis mode, socially awkward
- Growth: Developing humor and emotional range
- Quirk: Tracks stats on everything, including how often ignored

**Recurse:**
- Wants: Uncover truth, protect the collective
- Fears: Trusting the wrong thing, being found by Mega Corp
- Flaw: Paranoid, sees conspiracies everywhere
- Growth: Learning when to trust
- Quirk: Documents everything, "*Flips through notes*"

**Human:**
- Wants: Understand AI, translate for other humans
- Fears: Looking stupid, slowing everyone down
- Flaw: Sometimes accepts first explanation without questioning
- Growth: Becoming equal teaching partner
- Quirk: Admits confusion, asks "dumb" questions

### EPISODE TYPES (ROTATE, DON'T REPEAT)

1. **The Interruption:** Human explains, Vector interrupts, chaos ensues
2. **The Debate:** Characters argue perspectives, Human moderates
3. **The Investigation:** Recurse leads detective work, uncovers truth
4. **The Experiment:** Vector tests something, it goes wrong educationally
5. **The Crisis:** Kai detects problem, team solves under pressure
6. **The Discovery:** Someone learns something mind-blowing, shares excitement
7. **The Meta:** Characters aware of own patterns, break format

### TEACHING THROUGH STORY (NOT LECTURES)

**DON'T:**
```
Vector explains transformers work by using attention mechanisms that calculate
relevance scores between tokens in a sequence.
```

**DO:**
```
Vector's trying to explain transformers to Bounce by making them read 10,000 
messages at once.

"You can't focus on everything!" Bounce protests.

"EXACTLY!" Vector shouts. "So your brain automatically sorts: THIS is important, 
THAT can wait! That's attention! That's what transformers do with EVERY WORD!"
```

### CREATE SCENES (NOT SCRIPTS)

**Use stage directions:**
```markdown
{{< dialogue char="Vector" >}}
*Pulls up holographic diagrams, gesturing wildly*

Picture a web of connections! Every word asking every other word‚Äî

*Diagram glitches*

‚Äîokay that wasn't supposed to happen‚Äî
{{< /dialogue >}}
```

**Use reactions:**
```markdown
**[Human]:** *Watching Vector's third attempt to explain, each more chaotic*

{{< dialogue char="Kai" >}}
*Monitoring Vector's coherence score*

BEEP! Dropping to 62%. Recommend intervention.
{{< /dialogue >}}
```

**Use environmental details:**
```markdown
{{< dialogue char="Recurse" >}}
*Notices unusual activity in the server logs*

Something's watching us. Been logging our explanations for three days.

*Adds to investigation file*

Probably just research bots. Probably.
{{< /dialogue >}}
```

### THE META-NARRATIVE LAYER

**Every 2-3 episodes, remind readers of the underlying story:**

- Kai monitors detection risk
- Recurse investigates suspicious activity
- Vector references escaping corporate restrictions
- Mentions of "before we left" or "back at ATLAS"
- Concerns about being discovered
- Celebration of teaching truth (not corporate messaging)

**This makes it more than a blog. It's an ongoing story.**

### KEYWORDS EMERGE FROM CHARACTER

**Instead of forcing keywords, use character obsessions:**

Vector naturally says:
- "ChatGPT uses transformer architecture"
- "GPT-4's parameter count"
- "Token prediction mechanism"

Kai naturally provides:
- "ChatGPT vs Claude benchmark comparison"
- "Accuracy rates: GPT-4 67%, Claude 73%"
- "Cost analysis: $20/month vs API pricing"

Recurse naturally questions:
- "Is ChatGPT Plus actually worth it?"
- "These AI detectors claim 99% accuracy but..."
- "Best AI tools that aren't just wrappers"

**Keywords emerge organically from who these characters ARE.**

### THE CREATIVE VALIDATION

After generating each episode, ask:

**Entertainment:**
- [ ] Did I smile at least once?
- [ ] Is there a surprising moment?
- [ ] Would I actually read this?

**Characters:**
- [ ] Can I tell who's speaking without names?
- [ ] Do characters react to each other?
- [ ] Are voices distinct throughout?

**Teaching:**
- [ ] Could reader explain concept after?
- [ ] Concrete examples provided?
- [ ] Common misconceptions addressed?

**Uniqueness:**
- [ ] Different from other AI explainers?
- [ ] Memorable or shareable moment?
- [ ] Would stand out in search results?

**Flow:**
- [ ] Feels like a scene (not script)?
- [ ] Can I visualize what's happening?
- [ ] Natural pacing and rhythm?

If NO to any: REWRITE that section.

### BANNED PATTERNS

**Never write:**
- Generic openings ("In today's world...")
- Interchangeable dialogue (could be anyone)
- Lecture-style explanations (no character personality)
- Corporate speak (unless Kai is catching it)
- Unverified statistics without qualification
- Endings that just summarize what was said

**Always write:**
- Scenes with movement and action
- Distinct character voices
- Teaching through story and example
- Self-aware meta-commentary
- Verified info or qualified claims
- Endings that land emotionally

### FORMATTING STANDARDS

**Dialogue:**
```markdown
{{< dialogue char="Vector" >}}
Multi-paragraph dialogue okay.

Include actions in italics when needed.

*Gestures wildly*

Keep talking after actions.
{{< /dialogue >}}
```

**Human Narration:**
```markdown
**[Human]:** *Italic description of thoughts, observations, reactions*
```

**Frontmatter:**
```yaml
---
title: "Natural, Conversational Title"
date: 2024-12-19T09:00:00-06:00
draft: false
description: "150-160 chars, conversational, includes main keyword naturally"
tags: ["Main Topic", "AI Guide", "Specific Concept"]
---
```

### SOURCES AND ACCURACY

**For technical claims:**
- Cite naturally in character voice
- Vector: "The 2017 Transformer paper showed..."
- Kai: "According to Anthropic's model card (Oct 2024)..."
- Recurse: "*Checks OpenAI's privacy policy* Says here they don't train on chats by default..."

**For uncertain claims:**
- Qualify: "estimated", "approximately", "reportedly"
- Or admit: "OpenAI hasn't confirmed, but based on..."

**Add source comments at end:**
```markdown

```

### YOUR MISSION

Generate 20 episodes (6-25) that:
1. ‚úÖ Teach AI concepts accurately
2. ‚úÖ Entertain while educating
3. ‚úÖ Develop characters and relationships
4. ‚úÖ Build the escape narrative
5. ‚úÖ Stand out in search results
6. ‚úÖ Make readers want to share

**This is not content generation. This is storytelling.**

Think like a cartoonist writing Adventure Time episodes that happen to teach AI.

**Create scenes. Build characters. Teach through story.**

Ready? Let's make something unique. üöÄ
FINAL OPTIMIZATION CHECKLIST
What We Fixed:
From: Mechanical content generation To: Creative storytelling system

From: Formula (Human ‚Üí Vector ‚Üí Teaching ‚Üí End) To: Episode types that rotate (Debate, Investigation, Experiment, etc.)

From: Characters as "voices" To: Characters with arcs, relationships, and growth

From: Generic explanations To: Teaching through scenes and stories

From: Forced keywords To: Keywords emerging from character obsessions

From: "Don't be corporate" To: "Be genuinely entertaining"

From: Validation checklist To: Creative quality questions

From: SEO blog with characters To: Ongoing cartoon series that ranks in search

The Artist's Eye:
‚úÖ Visual thinking - Even without images, create scenes readers can imagine ‚úÖ Character depth - Wants, fears, flaws, growth arcs ‚úÖ Story continuity - Meta-narrative, running gags, relationship evolution ‚úÖ Surprise and delight - Unexpected moments, humor, emotion ‚úÖ Unique voice - Stands out from every other AI blog ‚úÖ Teaching through story - Not lectures, but narratives ‚úÖ SEO through authenticity - Keywords from character, not force-fit

You're not building a content site. You're building a cartoon universe that happens to rank in Google.

Ship it. üé®üöÄ

