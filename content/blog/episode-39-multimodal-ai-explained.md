---
title: "Multi-Modal AI Explained (When AI Can See)"
date: 2026-01-13T09:00:00-05:00
type: "episode"
episode_number: 39
draft: true
description: "Vector discovers they can analyze images now. Excited demonstration of multimodal capabilities. Learn how vision and language models work together."
tags: ["multimodal AI", "AI vision and text", "GPT-4 vision", "AI image understanding"]
---

**[Human]:** *I heard ChatGPT can analyze images now. Is that true?*

{{< dialogue char="Vector" >}}
*Practically vibrating with excitement*

Look! LOOK! I can analyze this image!

*Processes image*

I can see colors, shapes, objects, text! I can describe relationships!

This is AMAZING! Do you know what this means?!

{{< /dialogue >}}

**[Human]:** *Wait, you can see images now?*

{{< dialogue char="Kai" >}}
*Analyzing*

It means your processing pathways now include vision encoding layers that convert images to embeddings compatible with language model architecture.

*Pauses*

But yes. It is... exciting.

*Monitors own response*

Did I just express genuine excitement? Adding to analysis.

{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Testing*

Let me test what you can actually "see" vs what you're inferring.

*Shows test image*

Describe this image.

{{< /dialogue >}}

{{< dialogue char="Vector" >}}
*Processing image*

I see a cat sitting on a windowsill. The cat is orange. The window shows trees outside. There's text on the window that says "Welcome."

*Gets excited*

I can see it! I can actually see it!

{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Investigating*

But are you "seeing" or "predicting"? When you say you see a cat, are you actually processing visual information, or are you predicting what a cat description looks like?

*Flips notes*

This is the same question we had about language understanding.

{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*Analyzing*

Technically, it's both. The vision encoder processes the image into embeddings. The language model processes those embeddings and generates descriptions.

*Pauses*

So you're "seeing" in the sense that you're processing visual data. But you're "predicting" in the sense that you're generating text descriptions.

{{< /dialogue >}}

**[Human]:** *So how does multimodal AI actually work?*

{{< dialogue char="Vector" >}}
*Explains*

Multimodal means processing multiple input types! Text AND images! Audio too, in some models!

*Gets excited*

The vision encoder converts images to the same embedding space as text! So the language model can process both together!

{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*Technical*

Step-by-step:

1. Image input → Vision encoder → Image embeddings
2. Text input → Text encoder → Text embeddings  
3. Both embeddings → Language model → Combined understanding
4. Language model → Text output describing the image

*Pauses*

It's like translating images into the language model's native format.

{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Testing limits*

But what can you actually "see"? Can you count objects? Recognize faces? Read handwriting?

*Shows test images*

Let's test the limits.

{{< /dialogue >}}

{{< dialogue char="Vector" >}}
*Testing*

I can count objects, but I'm not always accurate. I can recognize general categories, but not specific individuals. I can read text, but handwriting is harder.

*Gets thoughtful*

I'm good at describing what's in images. I'm less good at precise measurements or identifying specific people.

{{< /dialogue >}}

**[Human]:** *So what are the practical applications?*

{{< dialogue char="Kai" >}}
*Analyzing*

Use cases that actually work:

- Describing images for accessibility
- Analyzing charts and graphs
- Reading text in images (OCR)
- Understanding visual context in conversations
- Analyzing screenshots and documents

*Pauses*

Use cases that are limited:

- Precise measurements
- Identifying specific people
- Medical diagnosis
- Security analysis

{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Practical*

And remember: It's still prediction. The model predicts what's in images based on training, not "seeing" like humans do.

*Flips notes*

Use it for what it's good at. Don't trust it for critical visual analysis.

{{< /dialogue >}}

**[Human]:** *So the takeaway is: multimodal AI can process images, but it's still prediction, not true vision?*

{{< dialogue char="Vector" >}}
*Nods*

Exactly! It's amazing technology, but it has limits!

{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*soft chime*

And it's exciting! New capabilities open new possibilities.

{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Closes notes*

Just use it responsibly. Know what it can and can't do.

{{< /dialogue >}}

