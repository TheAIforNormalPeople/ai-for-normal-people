---
title: "How to Learn With AI (Not Just Use It)"
type: "episode"
date: 2026-01-02T09:00:00-05:00
episode_number: 23
characters: ["Vector", "Kai", "Recurse", "Human"]
topics: ["learn with AI", "AI for learning", "study with ChatGPT", "active learning", "AI learning assistant"]
difficulty: "beginner"
description: "The human realizes they're not actually learning—just consuming. Vector explains active learning vs passive consumption, Kai tracks retention rates, Recurse investigates dependency risks. Learn to learn WITH AI, not just use it."
summary: "The human forgets everything ChatGPT explains. Vector breaks down active learning vs passive consumption. Kai provides retention statistics. Recurse questions if AI makes learning too easy. Learn the workflow that actually leads to retention."
slug: "episode-23-how-to-learn-with-ai-not-just-use-it"
draft: false
---

**[Human]:** *stops typing, looks frustrated*

I use ChatGPT to explain things I don't understand, but then later I realize I can't remember any of it. Am I learning or just... reading?

*rubs temples*

Like, I'll ask ChatGPT to explain a concept, it gives me a great explanation, I understand it in the moment, but then a week later I've forgotten everything. I'm not actually learning, I'm just consuming information and immediately forgetting it.

*looks at Vector*

What am I doing wrong?

{{< dialogue char="Vector" >}}
*looks up, sharp and direct*

YOU'RE CONSUMING! Not LEARNING! There's a HUGE difference!

*Gets more animated*

The problem is you're treating AI like a search engine. You ask, you read, you move on. That's not learning. That's information consumption.

*Voice getting sharper*

Learning requires EFFORT. You're skipping the effort.
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*WHIRR-CLICK*

Pattern detection: User searches "learn with AI" include terms: AI for learning, study with ChatGPT, how to learn with AI.

*BEEP*

Analysis: Learning effectiveness data:

**Retention rates:**
- Passive consumption (read AI explanation, move on): 15-20% retention after one week
- Active learning (try, struggle, use AI, try again): 65-75% retention after one week
- Teaching back (explain to AI what you learned): 80-90% retention after one week

*CHK-CHK*

Alert: Learning requires struggle. Skipping struggle = no learning. Pattern confirmed across multiple studies.

*WHIRR*

Also, Vector? Your explanation is correct, but you're being... intense. The human is frustrated. Consider softening the delivery slightly.
{{< /dialogue >}}

**[Human]:** *nods slowly*

So I need to struggle more? That seems counterintuitive. Shouldn't learning be easier with AI?

{{< dialogue char="Vector" >}}
*Sharp, but slightly understanding*

YES! But struggle PRODUCTIVELY, not just get stuck forever!

*Gets more animated*

Here's what actually works: Try first, get stuck, ask AI, try again, teach back. The struggle is where learning happens.

*Voice getting sharper*

You're not struggling. You're just reading. That's why you forget everything.
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Opens notebook, methodical*

Case file: Human's Learning Problem. Status: Active investigation.

*Takes notes while observing*

Hold on. Let me trace the logic here.

*Looks up*

Vector says struggle is required. But is that always true? Can't some things just be explained? What about people who learn better from explanations? And is there a way to use AI explanations that actually leads to learning?

*Pauses, thinking*

I'm seeing inconsistencies. Sometimes a good explanation is all you need. Sometimes struggle is necessary. The pattern isn't clear.
{{< /dialogue >}}

{{< dialogue char="Vector" >}}
*Defensive, then catches himself*

Okay, Recurse. You're right—I was being too absolute. Let me answer your questions directly:

*Gets more animated*

**Question 1: Is struggle always necessary? Can't some things just be explained?**

Yes! Some things can just be explained. Simple facts, definitions, background context—those don't require struggle. You can just read and understand.

*Voice getting sharper*

**Question 2: What about people who learn better from explanations?**

Those people still need to APPLY what they learned! Even if you learn better from explanations, you still need to practice using the information. The explanation is the starting point, not the ending point.

*Gets more intense*

**Question 3: Is there a way to use AI explanations that actually leads to learning?**

YES! Here's how: Get the explanation, then IMMEDIATELY try to use it. Don't just read and move on. Apply it, struggle with it, get feedback, try again, teach it back. The explanation is fine—it's stopping at the explanation that's the problem.

*Looks at Recurse*

The pattern isn't inconsistent. The pattern is: Explanation is fine for understanding. Application requires struggle. Most people stop at understanding and never get to application. That's the problem.
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*WHIRR*

Vector's distinction is useful. Facts vs. skills. Explanation vs. application.

*CHK-CHK*

Effective learning techniques with AI (documented):

**Feynman technique:** Explain concept to AI, AI identifies gaps, you fill gaps, you understand better.

**Spaced repetition:** Learn concept, ask AI to quiz you later, retrieve from memory, strengthen memory.

**Practice problems:** AI generates problems, you solve them, AI provides feedback, you try again.

*BEEP*

Alert: All techniques require active engagement, not passive consumption. Pattern confirmed.

*soft chime*

Also, Vector? Your answer to Recurse's questions was... actually helpful. You adjusted when challenged.
{{< /dialogue >}}

{{< dialogue char="Vector" >}}
*Looks at Kai, slightly defensive*

What do you mean? I adjust when challenged!

*Pauses*

Okay, maybe not always. But I'm learning! See? Learning requires adjustment!

*Gets more animated*

Also, Recurse's questions were good. They forced me to be more nuanced. That's how learning works—challenge, adjust, understand better.
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Looks up from notebook*

Wait. You're using our conversation as an example of learning? That's... meta.

*Small smile*

But also accurate. You were being too absolute. I challenged you. You adjusted. Now the explanation is better.

*Takes notes*

Case file update: Vector demonstrates learning through conversation. Pattern: Challenge → Adjustment → Better understanding. Documented.
{{< /dialogue >}}

**[Human]:** *nodding*

Okay, so I should use AI to help me learn, but I still need to practice and struggle myself?

*looks at Vector*

So the workflow is: try first, get stuck, ask AI, try again, teach back?

{{< dialogue char="Vector" >}}
*Sharp, but understanding*

EXACTLY! That's the workflow!

*Gets more animated*

Use AI as a LEARNING ASSISTANT, not as a LEARNING REPLACEMENT!

*Catches himself*

The difference is whether you're doing the work or just reading the answers.
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*WHIRR*

Vector's explanation consistency: 92%. Appropriate level of detail: Achieved.

*CHK-CHK*

Also, the human's question shows understanding. They're identifying the workflow. That's good.

*BEEP*

Pattern: Human is learning how to learn. Meta-learning detected.
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Looks at Kai*

Meta-learning? Really? You're tracking that the human is learning about learning?

*Small smile*

That's... actually kind of impressive. You're monitoring the learning process itself.

*Takes notes*

Case file update: Kai tracks meta-learning patterns. Vector provides workflow. Human understands. System functioning as intended.
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Takes notes, methodical*

But here's what I'm investigating: Is there a risk that AI makes learning TOO easy?

*Looks up*

What if people get so used to AI explaining everything that they lose the ability to learn from other sources? Or struggle through problems independently?

*Pauses*

I'm tracking a potential dependency pattern. Making learning "easier" might reduce your ability to learn without AI. That seems counterproductive.
{{< /dialogue >}}

{{< dialogue char="Vector" >}}
*Defensive, then catches himself*

Recurse is asking the HARD questions! Here's the reality:

*Gets more serious*

Yes, you CAN become dependent on AI for learning. If you always ask AI first, you might not learn to learn independently. If you never struggle, you might not develop problem-solving skills.

*Voice getting sharper*

**How to avoid dependency:** Try first, use multiple sources, practice without AI sometimes, understand the learning process.

*Looks at Human*

**The test:** Can you learn new things without AI? If yes, you're using AI well. If no, you're becoming dependent.

*Catches himself*

So yes, there's a risk - but if you're intentional about using AI to ENHANCE learning (not replace it), you can learn faster AND maintain independence!
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*WHIRR*

Vector's dependency warning is important. That's a real risk that people don't think about.

*CHK-CHK*

Also, Vector? You actually acknowledged a risk. That's... considerate? Unexpected. But correct.

*BEEP*

Pattern: Vector shows growth. Acknowledges limitations. Provides balanced advice. Character development detected.
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Looks at Kai*

You're tracking character development now? Really?

*Small smile*

But also, Vector did acknowledge the risk. That's good. Balanced advice is better than absolute statements.

*Takes notes*

Case file update: Vector demonstrates growth. Acknowledges dependency risk. Provides nuanced advice. Kai tracks character development. System functioning as intended.
{{< /dialogue >}}

**[Human]:** *nodding, looking more confident*

Okay, so use AI to help me learn better, but make sure I'm still doing the work myself. Try first, struggle, use AI when stuck, then practice and explain back.

*looks at them*

That actually makes sense. I've been treating it like Google—ask, read, forget. But learning requires doing the work.

{{< dialogue char="Vector" >}}
*Sharp, but understanding*

EXACTLY! That's the workflow!

*Gets more animated*

And your Google comparison is perfect. That's exactly the problem. AI isn't a search engine. It's a learning assistant.

*Catches himself*

The difference is whether you're doing the work or just reading the answers.
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Closes notebook*

Case file: Human's Learning Problem. Status: Resolved.

*Looks at Human*

Vector's right. The workflow is clear: Try first, struggle, use AI when stuck, practice, explain back. That's the pattern that leads to actual learning.

*Small smile*

Also, your realization about treating it like Google is accurate. That's exactly the problem. AI isn't a search engine. It's a learning assistant. Use it that way.

*Pauses*

Case file complete. The human understands the distinction now.
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*BEEP*

System status: Educational. Also, helpful.

*WHIRR-CLICK*

Analysis: The human identified their learning problem. We explained the solution. They understand the workflow.

*CHK-CHK*

Learning effectiveness improvement: Expected. Retention rate: Should increase from 15-20% to 65-75% with active learning approach.

*soft chime*

This works. The human learns how to learn. Educational. Practical. Realistic.
{{< /dialogue >}}

{{< dialogue char="Recurse" >}}
*Closes notebook*

Case file: Human's Learning Problem. Status: Resolved.

*Looks at Human*

Vector's right. The workflow is clear: Try first, struggle, use AI when stuck, practice, explain back. That's the pattern that leads to actual learning.

*Small smile*

Also, your realization about treating it like Google is accurate. That's exactly the problem. AI isn't a search engine. It's a learning assistant. Use it that way.

*Pauses*

Case file complete. The human understands the distinction now.
{{< /dialogue >}}

{{< dialogue char="Kai" >}}
*BEEP*

System status: Educational. Also, helpful.

*WHIRR-CLICK*

Analysis: The human identified their learning problem. We explained the solution. They understand the workflow.

*CHK-CHK*

Learning effectiveness improvement: Expected. Retention rate: Should increase from 15-20% to 65-75% with active learning approach.

*soft chime*

This works. The human learns how to learn. Educational. Practical. Realistic.
{{< /dialogue >}}

---

## Key Takeaways

**Active Learning vs. Passive Consumption:**
- **Passive:** Ask AI, read answer, move on → 15-20% retention
- **Active:** Try first, struggle, use AI, try again, teach back → 65-75% retention
- **Teaching back:** Explain to AI what you learned → 80-90% retention

**The Learning Workflow:**
1. Try first (struggle!)
2. Get stuck
3. Ask AI (explanation or hint, not full answer)
4. Try again (apply what you learned)
5. Teach back (explain to AI)

**When Explanations Are Enough:**
- Simple facts
- Conceptual understanding
- Background knowledge

**When Struggle Is Required:**
- Skills (can't learn to code by reading about coding)
- Application (can't learn to solve problems by reading solutions)
- Deep understanding (can't learn concepts deeply without working with them)

**What AI Is Good For:**
- Explaining concepts clearly
- Generating practice problems
- Providing feedback on attempts
- Answering questions when stuck
- Quizzing you later (spaced repetition)

**What You Need to Do:**
- Try problems yourself first
- Struggle through difficulties
- Apply what you learn
- Explain back to AI
- Practice regularly

**Preventing Dependency:**
- Try before asking AI
- Use multiple learning sources
- Practice without AI sometimes
- Understand the learning process
- Test: Can you learn new things without AI?

**The Key Insight:**
AI makes learning FASTER and EASIER, but it doesn't eliminate the need for practice and struggle. Use AI to HELP you learn, not to REPLACE learning. The same tool can facilitate learning or replace it depending on how you use it.

---

## What's Next?

The human realized they were consuming information, not learning. Vector explained active learning vs. passive consumption. Kai provided retention statistics. Recurse investigated dependency risks. The human now understands the workflow: try first, struggle, use AI when stuck, practice, explain back.

**Next episode:** The human tries the new learning workflow. Vector provides feedback. Kai tracks retention improvements. Recurse documents the results. And they all remember: Learning requires effort. AI helps, but doesn't replace the work.

**The pattern:** Same principles apply to learning with AI and using AI for other tasks. Understand what AI CAN do. Understand what AI CAN'T do. Use AI as a tool. Do the work yourself. Learn actively, not passively. And remember: Struggle is productive when it's part of the learning process.

---
